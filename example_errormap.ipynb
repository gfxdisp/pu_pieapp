{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import torch as pt\n",
    "\n",
    "from models.common import PUPieAPPPatch\n",
    "from loader.dataset import ImageLoader, image2patches\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to reference and distorted iamges\n",
    "ref_path = './example_images/ldr/i06.bmp'\n",
    "dist_path ='./example_images/ldr/i06_15_5.bmp'\n",
    "dynamic_range = 'ldr'\n",
    "\n",
    "# Parameters of the display model (Assuming peak and black level of a display on which LDR image is shown).\n",
    "# Set to 100 and 0.5 if unsure. The parameter is not used for HDR images as these are given in luminance values.\n",
    "lum_top = 100\n",
    "lum_bottom = 0.5\n",
    "\n",
    "# The quality assessment model operates on 64x64 patches sampled on a regular grid. \n",
    "# The shift specifies the window shift for sampling the patchs. The smaller the shift the more accurate the model is.\n",
    "stride = 32\n",
    "saved_state_model = './net_only.pt'\n",
    "state = pt.load(saved_state_model, map_location='cpu')\n",
    "loader = ImageLoader()\n",
    "\n",
    "def read_convert_pt_image(image_path):\n",
    "    image = imageio.imread(image_path)\n",
    "    image = pt.from_numpy(imageio.core.asarray(image))\n",
    "    image = image.permute(2,0,1)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise errormap\n",
    "\n",
    "The network takes 64x64 image patches. It applies the display model, PU transform and normalises every patch between 0 and 1 internally.\n",
    "\n",
    "The network takes as input image patches, dynamic range and top and bottom luminance of the display the image is shown on. If the image is an hdr image, the networks needs no top/bottom luminance parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read images and split them into patches (note: no processing is applied). \n",
    "image_ref = read_convert_pt_image(ref_path)\n",
    "image_dis = read_convert_pt_image(dist_path)\n",
    "\n",
    "ref_patches, img_patches, weights = image2patches(image_ref,image_dis,64,stride)\n",
    "\n",
    "# Create and load the model\n",
    "net = PUPieAPPPatch(state)\n",
    "net.eval()\n",
    "\n",
    "# Run the network with no gradient\n",
    "with pt.no_grad():\n",
    "    score, per_patch_score, per_patch_weight  = net(ref_patches, img_patches,im_type=dynamic_range, lum_top=top_l, lum_bottom=bot_l)\n",
    "    \n",
    "    \n",
    "    \n",
    "# Re-normalise the weight and the score between 0 and 1\n",
    "pp_score = np.squeeze(per_patch_score.cpu().numpy())\n",
    "pp_weight = np.squeeze(per_patch_weight.cpu().numpy())\n",
    "pp_weight_n = (pp_weight-np.min(pp_weight))/np.max(pp_weight -np.min(pp_weight))\n",
    "pp_score_n =  1-(pp_score-np.min(pp_score))/np.max((pp_score-np.min(pp_score)))\n",
    "\n",
    "# Assemble the image from the image patches and create an error map of the image patche scores, weighted by the patch weight\n",
    "image_ref,  error_map = loader.create_error_map(ref_patches.numpy(),weights,pp_score_n,pp_weight_n,shift_patch=stride)\n",
    "image_dist, error_map = loader.create_error_map(img_patches.numpy(),weights,pp_score_n,pp_weight_n,shift_patch=stride)\n",
    "\n",
    "# Set up the error map - blend it with the image: blend - blending parameter: how much of an image and how much of the\n",
    "# error map is displayed.\n",
    "blend = 0.8\n",
    "error_map[1:3,:,:] = 0.0  \n",
    "PUPieApp_blended_error_map = np.add(error_map*2*blend, (1-blend)*image_ref/255*3)\n",
    "\n",
    "plt.figure(figsize=(20, 6), dpi=100, facecolor='w', edgecolor='k')\n",
    "plt.subplot(131)\n",
    "plt.imshow(np.transpose(PUPieApp_blended_error_map/PUPieApp_blended_error_map.max(),(1,2,0)));\n",
    "plt.axis('off')\n",
    "plt.title('PUPieApp ERROR MAP')\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.imshow(np.transpose(image_dist/image_dist.max(),(1,2,0)));\n",
    "plt.axis('off')\n",
    "plt.title('DISTORTED')\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.imshow(np.transpose(np.sqrt((image_ref/image_ref.max()-image_dist/image_dist.max())**2),(1,2,0)))\n",
    "plt.axis('off')\n",
    "plt.title('RMSE MAP')\n",
    "\n",
    "#plt.savefig(\"example_error_map_pupieapp.png\", bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
